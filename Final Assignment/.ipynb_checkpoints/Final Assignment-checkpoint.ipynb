{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e64190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ed458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique(df):\n",
    "    objectColumns = df.dtypes[df.dtypes == object]\n",
    "    numberColumns = df.dtypes[df.dtypes != object]\n",
    "    text_to_num = list(objectColumns.index)\n",
    "    num_list = list(numberColumns.index)\n",
    "    #print('numerical colums are: ', num_list)\n",
    "    for i in range(len(text_to_num)):\n",
    "        col_name = text_to_num[i]\n",
    "        print(\"\\nthere are \" + str(df[col_name].nunique()) +\" different types in the column \"+ col_name +\":\\n\")\n",
    "        print(df[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_unique(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate the non residential source\n",
    "df = df[df.SOURCE == 'Residential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659f781",
   "metadata": {},
   "source": [
    "### based on the missing values, lets elimnate some columns to help fill in the dataset\n",
    "- get rid of cmplx_num and living_gba\n",
    "-- the number on the building probably doesnt hold much predicive value and we have more values in gba as well\n",
    "- get rid of the number of units - we have no missing values in rooms, bedrooms, bathrooms, or kitches so this should be fine\n",
    "- get rid of full address, city, state - none of these matter in prediciton\n",
    "- get rid of AYB, this information is better captured in eyb which has no missing values\n",
    "- get rid of sale number and building number\n",
    "- get rid of national grid, longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a746f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"CMPLX_NUM\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"NUM_UNITS\",\"AYB\",\"SALEDATE\",\"Unnamed: 0\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09277b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"SALE_NUM\",\"BLDG_NUM\",\"LIVING_GBA\",\"FULLADDRESS\",\"CITY\", \"STATE\",\"NATIONALGRID\",\"X\",\"Y\",\"SOURCE\",\"STORIES\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1033c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets also get rid of census block, that should be convered well enough by census tract\n",
    "#roof, exterior wall, interior wall, have too many values missing to really be helpful\n",
    "# honestly how many houses will have more than one kitchen\n",
    "# more than half of the year remodel missing won't be a helpful predictor\n",
    "df.drop([\"EXTWALL\",\"ROOF\",\"INTWALL\",\"KITCHENS\",\"CENSUS_BLOCK\", \"YR_RMDL\" ], inplace=True, axis=1)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c87867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subneighborhood seems unimportant and has several missing values\n",
    "#stories and quadrant are missing values and seem to be small enough to eliminate but still have a\n",
    "#good amount of data\n",
    "\n",
    "df.drop([\"ASSESSMENT_SUBNBHD\", \"QUADRANT\"], inplace=True, axis=1)\n",
    "\n",
    "# lets get rid of the entries where we only have one value\n",
    "# only keep the rows if zipcode is not null\n",
    "df = df[df.ZIPCODE.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdd65f",
   "metadata": {},
   "source": [
    "## Price is the most important data we want to fill in\n",
    "### Find a similar spread in another graph and match based on bins or quantile\n",
    "### We should also be able to eliminate other less useful pieces of information like fireplaes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7772bf",
   "metadata": {},
   "source": [
    "# Part A: Cleaning the data\n",
    "\n",
    "## Implement a sensible approabch for dealing with missing data\n",
    "### After that\n",
    "- change all the values in the dataset into numerical values\n",
    "- substitute dummy columns for categorical variables\n",
    "- eliminate any colums that may not be relevant to objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"QUALIFIED\", \"HEAT\",\"USECODE\",\"LATITUDE\",\"LONGITUDE\",\"CENSUS_TRACT\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PRICE\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacde776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column that adds rooms baths and half baths \n",
    "# plot against stories\n",
    "df['ALL_RM'] = df.apply(lambda row: row.BATHRM + row.HF_BATHRM + row.ROOMS + row.BEDRM, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ROOMS', y='PRICE', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ALL_RM', y='PRICE', style='o')\n",
    "#that results in the same distribution, so lets get rid of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='EYB', y='PRICE', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at ward - it should have 8 categories, perhaps we can bin that and get an average price\n",
    "# trim all the values \n",
    "df[\"WARD\"] = df[\"WARD\"].str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WARD'] = df['WARD'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df = df['WARD'].value_counts()\n",
    "print(w_df)\n",
    "w_options = df['WARD'].value_counts().keys().to_list()\n",
    "w_count = df['WARD'].value_counts().to_list()\n",
    "print(w_options)\n",
    "print(w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a13383",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(w_options, w_count, width = 0.3, color=\"blue\")\n",
    "plt.ylabel('Number of houses')\n",
    "plt.xlabel('WARD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupby('WARD', as_index=False)['PRICE'].mean()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot(x=\"WARD\", y=\"PRICE\", style = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='GBA', y='PRICE', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7050c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='FIREPLACES', y='PRICE', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb844a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df = df['ZIPCODE'].value_counts()\n",
    "print(z_df)\n",
    "z_options = df['ZIPCODE'].value_counts().keys().to_list()\n",
    "z_count = df['ZIPCODE'].value_counts().to_list()\n",
    "print(z_options)\n",
    "print(z_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd69362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ZIPCODE', y='PRICE', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ae052",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupby('ZIPCODE', as_index=False)['PRICE'].mean()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28626278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ROOMS', y='BEDRM', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ROOMS', y='ALL_RM', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ccc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ROOMS', y='BATHRM', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82805ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='ROOMS', y='HF_BATHRM', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='HF_BATHRM', y='PRICE', style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ea718",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_df = df['AC'].value_counts()\n",
    "print(ac_df)\n",
    "ac_options = df['AC'].value_counts().keys().to_list()\n",
    "ac_count = df['AC'].value_counts().to_list()\n",
    "print(ac_options)\n",
    "print(ac_count)\n",
    "\n",
    "plt.bar(ac_options, ac_count, width = 0.3, color=\"blue\")\n",
    "plt.ylabel('Number of houses')\n",
    "plt.xlabel('AC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159548ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = df.groupby('AC', as_index=False)['PRICE'].mean()\n",
    "ac.head()\n",
    "\n",
    "ac.plot(x=\"AC\", y=\"PRICE\", style = 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = df['CNDTN'].value_counts()\n",
    "print(c_df)\n",
    "c_options = df['CNDTN'].value_counts().keys().to_list()\n",
    "c_count = df['CNDTN'].value_counts().to_list()\n",
    "print(c_options)\n",
    "print(c_count)\n",
    "\n",
    "plt.bar(c_options, c_count, width = 0.3, color=\"blue\")\n",
    "plt.ylabel('Number of houses')\n",
    "plt.xlabel('CNDTN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a634eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df.groupby('CNDTN', as_index=False)['PRICE'].mean()\n",
    "\n",
    "c.plot(x=\"CNDTN\", y=\"PRICE\", style = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae847c2",
   "metadata": {},
   "source": [
    "# Lets fill in price based on the average from the ward\n",
    "## there are 8 wards and we can match up the average from that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e591042",
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_op = test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ward_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eaecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ward_op[0][0])\n",
    "print(ward_op[0][1])\n",
    "print(len(ward_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ward_price_lookup(cols):\n",
    "    ward = cols[0]\n",
    "    price = cols[1]\n",
    "    if pd.isnull(price):\n",
    "        if ward == ward_op[0][0]:\n",
    "            return ward_op[0][1]\n",
    "        elif ward == ward_op[1][0]:\n",
    "            return ward_op[1][1]\n",
    "        elif ward == ward_op[2][0]:\n",
    "            return ward_op[2][1]\n",
    "        elif ward == ward_op[3][0]:\n",
    "            return ward_op[3][1]\n",
    "        elif ward == ward_op[4][0]:\n",
    "            return ward_op[4][1]\n",
    "        elif ward == ward_op[5][0]:\n",
    "            return ward_op[5][1]\n",
    "        elif ward == ward_op[6][0]:\n",
    "            return ward_op[6][1]\n",
    "        else:\n",
    "            return ward_op[7][1]\n",
    "    \n",
    "    else:\n",
    "        return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PRICE'] = df[['WARD','PRICE']].apply(ward_price_lookup,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19b55d",
   "metadata": {},
   "source": [
    "## Now that we have all the price values filled in, lets delete other irrelevant columns and convert everything to numerical values and create dummies for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104c1b9",
   "metadata": {},
   "source": [
    "### ward and zipcode should fill in the genral area so get rid of nbhd and square\n",
    "### all room was a variable I made, so delete it. - in that there was a linear correlation between the number of rooms and all rooms, so eliminate everything but rooms\n",
    "### Structure has less options and should be able to fill in for style\n",
    "### there are less condidtions than grades so eliminate grade\n",
    "### EYB should cover what the last mod does\n",
    "### Fireplaces does not have much correlation or relevance\n",
    "### GBA should be enough to go off of, eliminate land area\n",
    "### AC is unhelpful since 0 means nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e109395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ASSESSMENT_NBHD','SQUARE', 'ALL_RM','STYLE','GIS_LAST_MOD_DTTM', 'FIREPLACES','ZIPCODE','LANDAREA','AC'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6233f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only bathrooms and rooms since there is a pretty linear relationship with both\n",
    "df.drop(['HF_BATHRM', 'BEDRM','BATHRM'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924cbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CNDTN'], inplace=True, axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebcf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in the end we have kept bathrooms bedrooms EYB price GBA struct condition and ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b182ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectColumns = df.dtypes[df.dtypes == object]\n",
    "numberColumns = df.dtypes[df.dtypes != object]\n",
    "text_to_num = list(objectColumns.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75210962",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df, columns=text_to_num, drop_first=True) \n",
    "X = X.astype('int')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22369849",
   "metadata": {},
   "source": [
    "# Part B: Dimmensional Reduction\n",
    "\n",
    "## Use SVD and PCA\n",
    "- in each case show eigenvectors and eigenvalues\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96642641",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['PRICE'], inplace=True, axis=1)\n",
    "X = X.T\n",
    "y = df['PRICE']\n",
    "y = y.astype('int')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c22e13",
   "metadata": {},
   "source": [
    "Using PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.dot(X, X.T)\n",
    "v, w = np.linalg.eig(C)\n",
    "print('Eigen-values: v=\\n', v,'\\n')\n",
    "print('Eigen-vectors: w=\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = np.cumsum(v)/sum(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sv = np.insert(sv, 0, 0)\n",
    "plt.step(list(range(len(sv))), sv)\n",
    "plt.show()\n",
    "print('sv =', sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ebf07b",
   "metadata": {},
   "source": [
    "Use SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29575b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(X, full_matrices=False)\n",
    "print('Eigen-vectors: U=\\n', U, U.shape,'\\n')\n",
    "print('Eigen-values: s=', s, s.shape)\n",
    "print('Eigen-vectors: VT=', VT.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv2 = np.cumsum(s)/sum(s)\n",
    "#sv = np.insert(sv, 0, 0)\n",
    "plt.step(list(range(len(sv2))), sv2)\n",
    "plt.show()\n",
    "print('sv2 =', sv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3e521",
   "metadata": {},
   "source": [
    "## Show Scree Plot\n",
    "\n",
    "### Answer the question\n",
    "- How many dimmensitons of the dataset should be used to retain over 90% of the data variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a23282",
   "metadata": {},
   "source": [
    "PCA converges around 4\n",
    "SVD converges at 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7db90",
   "metadata": {},
   "source": [
    "# Part C\n",
    "## Divide dataset\n",
    "- Use Linear regression model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df, columns=text_to_num, drop_first=True) \n",
    "X = X.astype('int')\n",
    "X.drop(['PRICE'], inplace=True, axis=1)\n",
    "y = df['PRICE']\n",
    "y = y.astype('int')\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "Xstd = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xstd, y, test_size=0.25, random_state=45) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0872e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coefficient', lm.coef_)\n",
    "print(\"intercept:\",lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dba4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)\n",
    "print(len(X_test))\n",
    "print(type(predictions))\n",
    "print(predictions.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(len(predictions))\n",
    "print(len(y_test))\n",
    "print(lm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0fa3d",
   "metadata": {},
   "source": [
    "\n",
    "## Convert Price into categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f54b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_price_category(cols):\n",
    "    for price in cols:\n",
    "        if price <= 30000:\n",
    "            return 0\n",
    "        elif price <= 60000:\n",
    "            return 1\n",
    "        elif price <= 90000:\n",
    "            return 2\n",
    "        elif price<= 130000:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PRICE'] = df[['PRICE']].apply(convert_price_category,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9210c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['PRICE']\n",
    "plt.hist(y, bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xstd, y, test_size=0.25, random_state=45) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a927c7",
   "metadata": {},
   "source": [
    "\n",
    "### Use each of the following to predict\n",
    "- Logistic Regression\n",
    "- Neural Network\n",
    "- Naive Bays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf827a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_predictions = log_reg.predict(X_test)\n",
    "print(Log_predictions.shape, Log_predictions.dtype)\n",
    "print(y_test.shape, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14885a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, Log_predictions)\n",
    "print(cm)  \n",
    "score = accuracy_score(y_test, Log_predictions)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697913a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g1(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "def g2(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "def g1_prime(x):\n",
    "    return g1(x) * (1 - g1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with number of neurons in hidden layer \n",
    "# display confusion matrix and classification results\n",
    "\n",
    "def NN(X, y, n_h, n_y, alpha, iterations):\n",
    "\tstage_1 = iterations//2; alpha2 = alpha/2.\n",
    "\tstage_2 = iterations//1.75; alpha3 = alpha/4.\n",
    "\tstage_3 = iterations//1.5; alpha4 = alpha/8.\n",
    "\tcost_list = [[],[]]\n",
    "\tm = X.shape[1]\n",
    "\tn_x = X.shape[0]\n",
    "\tW1 = np.random.randn(n_h, n_x)\n",
    "\tb1 = np.random.randn(n_h, 1)\n",
    "\tW2 = np.random.randn(n_y, n_h)\n",
    "\tb2 = np.random.randn(n_y, 1)\n",
    "\tfor i in range(iterations):\n",
    "\t\tZ1 = np.dot(W1, X) + b1\n",
    "\t\tA1 = g1(Z1)\n",
    "\t\tZ2 = np.dot(W2, A1) + b2\n",
    "\t\tA2 = g2(Z2)\n",
    "\t\tif i%100 == 0:\n",
    "\t\t\tcost = -np.sum(y*np.log(A2) + (1-y)*np.log(1-A2))\n",
    "\t\t\tcost_list[0].append(i)\n",
    "\t\t\tcost_list[1].append(cost)\n",
    "\t\tdZ2 = A2 - y\n",
    "\t\tdW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "\t\tdb2 = (1/m) * np.sum(dZ2)\n",
    "\t\tdZ1 = np.dot(W2.T, dZ2) * g1_prime(Z1)\n",
    "\t\tdW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "\t\tdb1 = (1/m) * np.sum(dZ1)\n",
    "\t\tW2 = W2 - alpha * dW2\n",
    "\t\tb2 = b2 - alpha * db2\n",
    "\t\tW1 = W1 - alpha * dW1\n",
    "\t\tb1 = b1 - alpha * db1\n",
    "\t\tif i>stage_1: alpha = alpha2\n",
    "\t\telif i>stage_2: alpha = alpha3\n",
    "\t\telif i>stage_3: alpha = alpha4\n",
    "\treturn W1, b1, W2, b2, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_h is the number of hidden layers - this is what we will play with\n",
    "#n_y is the number in the output layer - we are only looking for 1 output\n",
    "n_h = 2; n_y = 1; n_h2=2\n",
    "alpha = 0.05\n",
    "iterations = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac50aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_N = y_train.values.reshape(-1,1)\n",
    "print(y_train_N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7338b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train_N.shape)\n",
    "print(X_train.T.shape, y_train_N.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335159eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2, cost_list = NN(X_train.T, y_train_N.T, n_h, n_y, alpha, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_2, b1_2, W2_2, b2_2, cost_list_2 = NN(X_train.T, y_train_N.T, n_h2, n_y, alpha, iterations)\n",
    "\n",
    "print('W1=',W1, '\\n', 'b1=',b1, '\\n', 'W2=',W2, '\\n', 'b2=',b2)\n",
    "plt.plot(cost_list[0][1:], cost_list[1][1:], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('With two hidden layers:\\n', 'W1=',W1_2, '\\n', 'b1=',b1_2, '\\n', 'W2=',W2_2, '\\n', 'b2=',b2_2)\n",
    "plt.plot(cost_list_2[0][1:], cost_list_2[1][1:], 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b339bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = np.dot(W1, X_test.T) + b1\n",
    "A1 = g1(Z1)\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = g2(Z2)\n",
    "\n",
    "NN_predictions = A2.copy()\n",
    "NN_predictions[A2 < 0.5] = 0\n",
    "NN_predictions[A2 > 0.5] = 1\n",
    "print('A2=',A2)\n",
    "print('predictions=',NN_predictions)\n",
    "\n",
    "print(y_test.shape, NN_predictions.T.shape)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, NN_predictions.T))  \n",
    "print(classification_report(y_test, NN_predictions.T))\n",
    "NNscore = accuracy_score(y_test, NN_predictions.T)\n",
    "print(NNscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d37d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(np.mean(attribute), np.std(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "\n",
    "import math\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    if stdev == 0: return 0\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906981c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "import random\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f490f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "y = y.values.reshape(106695,1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ff113",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.append(X, y, 1)\n",
    "print(data.shape)\n",
    "# Split data into training and testing\n",
    "splitRatio = 0.67\n",
    "trainingSet, testSet = splitDataset(data, splitRatio)\n",
    "print(len(trainingSet))\n",
    "print(len(testSet))\n",
    "# Apply the NaÃ¯ve Bayes Algorithm\n",
    "summaries = summarizeByClass(trainingSet)\n",
    "predictions = getPredictions(summaries, testSet)\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73bedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f353550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d243ffe5",
   "metadata": {},
   "source": [
    "# Finally, validate the models with testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0725cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
